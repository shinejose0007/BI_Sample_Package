{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc58a24d-f711-4e68-943d-d206e8e28783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MITARBEITER loaded: mitarbeiter.csv\n",
      "LIEFERANTEN loaded: lieferanten.xlsx\n",
      "No DQ issues (basic checks).\n",
      "KPI-Tabelle in DW geschrieben (rows=60)\n",
      "Exports erzeugt: outputs/kpi_export.csv outputs/kpi_export.xlsx outputs/kpi_export.parquet\n",
      "Dashboard geschrieben: outputs/dashboard.html\n",
      "Pipeline finished.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "etl_reporting.py - Extended Demo for BI & Reporting\n",
    "Features:\n",
    "- Reads from SQLite demo source DB (or create demo data)\n",
    "- Reads additional sources: mitarbeiter.csv, lieferanten.xlsx\n",
    "- ETL transformations, KPI computation\n",
    "- Data quality checks\n",
    "- Writes KPI table to DW (SQLite), and exports CSV, Excel, Parquet\n",
    "- Generates interactive HTML dashboard (plotly.graph_objects)\n",
    "- Uses config.json for configuration\n",
    "\"\"\"\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "import json\n",
    "\n",
    "# Load config\n",
    "CONFIG_PATH = os.environ.get(\"CONFIG_PATH\", \"config.json\")\n",
    "with open(CONFIG_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "SOURCE_DB_URI = os.environ.get(\"SOURCE_DB_URI\", cfg.get(\"SOURCE_DB_URI\", \"sqlite:///source_demo.db\"))\n",
    "DW_DB_URI = os.environ.get(\"DW_DB_URI\", cfg.get(\"DW_DB_URI\", \"sqlite:///dw_demo.db\"))\n",
    "MITARBEITER_CSV = cfg.get(\"MITARBEITER_CSV\", \"mitarbeiter.csv\")\n",
    "LIEFERANTEN_XLSX = cfg.get(\"LIEFERANTEN_XLSX\", \"lieferanten.xlsx\")\n",
    "DASHBOARD_HTML = cfg.get(\"DASHBOARD_HTML\", \"outputs/dashboard.html\")\n",
    "CSV_EXPORT = cfg.get(\"CSV_EXPORT\", \"outputs/kpi_export.csv\")\n",
    "XLSX_EXPORT = cfg.get(\"XLSX_EXPORT\", \"outputs/kpi_export.xlsx\")\n",
    "PARQUET_EXPORT = cfg.get(\"PARQUET_EXPORT\", \"outputs/kpi_export.parquet\")\n",
    "\n",
    "# ---------------------------\n",
    "# Demo data creation (if needed)\n",
    "# ---------------------------\n",
    "def create_demo_source_db(engine):\n",
    "    rng = np.random.default_rng(42)\n",
    "    n_orders = 500\n",
    "    start_date = datetime(2024, 1, 1)\n",
    "    orders = pd.DataFrame({\n",
    "        \"order_id\": np.arange(1, n_orders+1),\n",
    "        \"site\": rng.choice([\"Bremen\", \"Hamburg\", \"Rendsburg\"], size=n_orders, p=[0.5,0.3,0.2]),\n",
    "        \"created_at\": [start_date + timedelta(days=int(x)) for x in rng.integers(0, 600, n_orders)],\n",
    "        \"completed_at\": [None]*n_orders,\n",
    "        \"cost\": rng.normal(10000, 2000, n_orders).round(2)\n",
    "    })\n",
    "    for i in orders.sample(frac=0.8, random_state=1).index:\n",
    "        lead = int(rng.integers(10, 120))\n",
    "        orders.at[i, \"completed_at\"] = (orders.at[i, \"created_at\"] + timedelta(days=lead)).strftime(\"%Y-%m-%d\")\n",
    "    orders[\"created_at\"] = orders[\"created_at\"].dt.strftime(\"%Y-%m-%d\")\n",
    "    production = pd.DataFrame({\n",
    "        \"prod_id\": np.arange(1, 301),\n",
    "        \"site\": rng.choice([\"Bremen\", \"Hamburg\", \"Rendsburg\"], size=300),\n",
    "        \"start_date\": [(start_date + timedelta(days=int(x))).strftime(\"%Y-%m-%d\") for x in rng.integers(0, 600, 300)],\n",
    "        \"percent_complete\": rng.integers(0, 101, 300),\n",
    "        \"defects\": rng.poisson(0.8, 300)\n",
    "    })\n",
    "    employees = pd.DataFrame({\n",
    "        \"emp_id\": [1,2,3],\n",
    "        \"name\": [\"Team A\", \"Team B\", \"Team C\"],\n",
    "        \"site\": [\"Bremen\", \"Hamburg\", \"Rendsburg\"]\n",
    "    })\n",
    "    orders.to_sql(\"orders\", engine, if_exists=\"replace\", index=False)\n",
    "    production.to_sql(\"production\", engine, if_exists=\"replace\", index=False)\n",
    "    employees.to_sql(\"employees\", engine, if_exists=\"replace\", index=False)\n",
    "    print(\"Demoquelle erstellt: orders, production, employees\")\n",
    "\n",
    "# ---------------------------\n",
    "# Read additional sources\n",
    "# ---------------------------\n",
    "def read_additional_sources():\n",
    "    # mitarbeiter.csv\n",
    "    try:\n",
    "        mit = pd.read_csv(MITARBEITER_CSV)\n",
    "        print(f\"MITARBEITER loaded: {MITARBEITER_CSV}\")\n",
    "    except Exception as e:\n",
    "        mit = pd.DataFrame()\n",
    "        print(\"MITARBEITER not loaded:\", e)\n",
    "    # lieferanten.xlsx\n",
    "    try:\n",
    "        liefer = pd.read_excel(LIEFERANTEN_XLSX)\n",
    "        print(f\"LIEFERANTEN loaded: {LIEFERANTEN_XLSX}\")\n",
    "    except Exception as e:\n",
    "        liefer = pd.DataFrame()\n",
    "        print(\"LIEFERANTEN not loaded:\", e)\n",
    "    return mit, liefer\n",
    "\n",
    "# ---------------------------\n",
    "# Extract\n",
    "# ---------------------------\n",
    "def extract_data(engine):\n",
    "    orders = pd.read_sql(\"SELECT * FROM orders\", con=engine)\n",
    "    production = pd.read_sql(\"SELECT * FROM production\", con=engine)\n",
    "    employees = pd.read_sql(\"SELECT * FROM employees\", con=engine)\n",
    "    return orders, production, employees\n",
    "\n",
    "# ---------------------------\n",
    "# Transform / KPI\n",
    "# ---------------------------\n",
    "def transform_data(orders, production, mit, liefer):\n",
    "    orders = orders.copy()\n",
    "    orders['created_at'] = pd.to_datetime(orders['created_at'])\n",
    "    orders['completed_at'] = pd.to_datetime(orders['completed_at'], errors='coerce')\n",
    "    orders['lead_days'] = (orders['completed_at'] - orders['created_at']).dt.days\n",
    "    orders['is_completed'] = orders['completed_at'].notna().astype(int)\n",
    "    orders['year_month'] = orders['created_at'].dt.to_period('M').astype(str)\n",
    "    kpi_orders = orders.groupby(['site', 'year_month']).agg(\n",
    "        orders_count=('order_id', 'count'),\n",
    "        completed_count=('is_completed', 'sum'),\n",
    "        avg_lead_days=('lead_days', 'mean'),\n",
    "        cost_total=('cost', 'sum')\n",
    "    ).reset_index()\n",
    "    kpi_orders['avg_lead_days'] = kpi_orders['avg_lead_days'].fillna(0).round(2)\n",
    "    production = production.copy()\n",
    "    production['start_date'] = pd.to_datetime(production['start_date'])\n",
    "    production['year_month'] = production['start_date'].dt.to_period('M').astype(str)\n",
    "    kpi_prod = production.groupby(['site', 'year_month']).agg(\n",
    "        avg_percent_complete=('percent_complete', 'mean'),\n",
    "        defects_total=('defects', 'sum'),\n",
    "        production_count=('prod_id', 'count')\n",
    "    ).reset_index()\n",
    "    kpi_prod['avg_percent_complete'] = kpi_prod['avg_percent_complete'].round(2)\n",
    "    kpi = pd.merge(kpi_orders, kpi_prod, how='outer', on=['site', 'year_month']).fillna(0)\n",
    "    kpi['completion_rate'] = (kpi['completed_count'] / kpi['orders_count']).replace([np.inf, -np.inf], 0).fillna(0).round(3)\n",
    "    try:\n",
    "        kpi['year_month_date'] = pd.to_datetime(kpi['year_month'] + '-01')\n",
    "    except Exception:\n",
    "        kpi['year_month_date'] = pd.NaT\n",
    "    kpi['generated_at'] = pd.Timestamp.now()\n",
    "    if not mit.empty and 'site' in mit.columns:\n",
    "        emp_counts = mit.groupby('site').size().reset_index(name='employee_count')\n",
    "        kpi = kpi.merge(emp_counts, on='site', how='left').fillna({'employee_count':0})\n",
    "    else:\n",
    "        kpi['employee_count'] = 0\n",
    "    if not liefer.empty:\n",
    "        kpi['supplier_count'] = len(liefer)\n",
    "    else:\n",
    "        kpi['supplier_count'] = 0\n",
    "    return kpi\n",
    "\n",
    "# ---------------------------\n",
    "# Data Quality Checks\n",
    "# ---------------------------\n",
    "def data_quality_checks(orders, production):\n",
    "    issues = []\n",
    "    if orders['order_id'].isnull().any():\n",
    "        issues.append(\"Nulls in orders.order_id\")\n",
    "    if orders['created_at'].isnull().any():\n",
    "        issues.append(\"Nulls in orders.created_at\")\n",
    "    if orders['order_id'].duplicated().any():\n",
    "        issues.append(\"Duplicated order_id in orders\")\n",
    "    if (orders['cost'] < 0).any():\n",
    "        issues.append(\"Negative cost values found\")\n",
    "    if production['percent_complete'].lt(0).any() or production['percent_complete'].gt(100).any():\n",
    "        issues.append(\"percent_complete out of range 0-100\")\n",
    "    return issues\n",
    "\n",
    "# ---------------------------\n",
    "# Load/Exports\n",
    "# ---------------------------\n",
    "def load_to_dw(engine_dw, kpi_df):\n",
    "    kpi_df.to_sql(\"kpis\", engine_dw, if_exists=\"replace\", index=False)\n",
    "    print(f\"KPI-Tabelle in DW geschrieben (rows={len(kpi_df)})\")\n",
    "\n",
    "def export_all(kpi_df):\n",
    "    PathDir = os.path.dirname(CSV_EXPORT)\n",
    "    if PathDir and not os.path.exists(PathDir):\n",
    "        os.makedirs(PathDir, exist_ok=True)\n",
    "    kpi_df.to_csv(CSV_EXPORT, index=False)\n",
    "    kpi_df.to_excel(XLSX_EXPORT, index=False)\n",
    "    try:\n",
    "        kpi_df.to_parquet(PARQUET_EXPORT, index=False)\n",
    "    except Exception as e:\n",
    "        print(\"Parquet export failed (optional):\", e)\n",
    "    print(\"Exports erzeugt:\", CSV_EXPORT, XLSX_EXPORT, PARQUET_EXPORT)\n",
    "\n",
    "# ---------------------------\n",
    "# Dashboard (graph_objects)\n",
    "# ---------------------------\n",
    "def generate_dashboard(kpi_df, filename=DASHBOARD_HTML):\n",
    "    try:\n",
    "        import plotly.graph_objects as go\n",
    "        import plotly.io as pio\n",
    "    except Exception as e:\n",
    "        print(\"Plotly not available. Skipping dashboard. Error:\", e)\n",
    "        return\n",
    "    if kpi_df.empty:\n",
    "        print(\"No KPI data for dashboard.\")\n",
    "        return\n",
    "    kpi_df = kpi_df.sort_values(['site','year_month_date'])\n",
    "    fig = go.Figure()\n",
    "    for site, df_site in kpi_df.groupby('site'):\n",
    "        fig.add_trace(go.Scatter(x=df_site['year_month_date'], y=df_site['completion_rate'],\n",
    "                                 mode='lines+markers', name=str(site)))\n",
    "    fig.update_layout(title='Completion Rate je Standort (Monat)', xaxis_title='Monat', yaxis_title='Completion Rate')\n",
    "    fig2 = go.Figure()\n",
    "    for site, df_site in kpi_df.groupby('site'):\n",
    "        fig2.add_trace(go.Bar(x=df_site['year_month_date'], y=df_site['orders_count'], name=str(site)))\n",
    "    fig2.update_layout(title='Bestellanzahl je Monat / Standort', barmode='group')\n",
    "    html = \"<html><head><meta charset='utf-8'></head><body>\"\n",
    "    html += \"<h1>BI Dashboard - KPI Export</h1>\"\n",
    "    html += pio.to_html(fig, include_plotlyjs='cdn', full_html=False)\n",
    "    html += \"<hr>\"\n",
    "    html += pio.to_html(fig2, include_plotlyjs=False, full_html=False)\n",
    "    html += \"</body></html>\"\n",
    "    outdir = os.path.dirname(filename)\n",
    "    if outdir and not os.path.exists(outdir):\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(html)\n",
    "    print(\"Dashboard geschrieben:\", filename)\n",
    "\n",
    "# ---------------------------\n",
    "# Main\n",
    "# ---------------------------\n",
    "def main():\n",
    "    engine_src = create_engine(SOURCE_DB_URI, echo=False)\n",
    "    engine_dw = create_engine(DW_DB_URI, echo=False)\n",
    "    with engine_src.connect() as conn:\n",
    "        res = conn.execute(text(\"SELECT name FROM sqlite_master WHERE type='table'\"))\n",
    "        tables = [r[0] for r in res.fetchall()]\n",
    "    if not tables:\n",
    "        create_demo_source_db(engine_src)\n",
    "    mit, liefer = read_additional_sources()\n",
    "    orders, production, employees = extract_data(engine_src)\n",
    "    dq = data_quality_checks(orders, production)\n",
    "    if dq:\n",
    "        print(\"Data Quality Issues:\", dq)\n",
    "    else:\n",
    "        print(\"No DQ issues (basic checks).\")\n",
    "    kpi = transform_data(orders, production, mit, liefer)\n",
    "    load_to_dw(engine_dw, kpi)\n",
    "    export_all(kpi)\n",
    "    generate_dashboard(kpi)\n",
    "    print(\"Pipeline finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e31e66-3527-4240-b06f-58f49a78d3f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (15.0.2)\n",
      "Requirement already satisfied: numpy<2,>=1.16.6 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from pyarrow) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3113139-b6a7-4672-a2ee-553332191859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fastparquetNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading fastparquet-2024.11.0-cp312-cp312-win_amd64.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: pandas>=1.5.0 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from fastparquet) (1.26.4)\n",
      "Collecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.11.0-cp312-cp312-win_amd64.whl.metadata (681 bytes)\n",
      "Requirement already satisfied: fsspec in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from fastparquet) (2024.6.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from fastparquet) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\envs\\mynewenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "Downloading fastparquet-2024.11.0-cp312-cp312-win_amd64.whl (673 kB)\n",
      "   ---------------------------------------- 0.0/673.3 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 256.0/673.3 kB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  665.6/673.3 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 673.3/673.3 kB 4.7 MB/s eta 0:00:00\n",
      "Downloading cramjam-2.11.0-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 0.5/1.7 MB 10.9 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 10.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 1.6/1.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.7/1.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 7.8 MB/s eta 0:00:00\n",
      "Installing collected packages: cramjam, fastparquet\n",
      "Successfully installed cramjam-2.11.0 fastparquet-2024.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~atplotlib (C:\\Users\\shinejose\\AppData\\Roaming\\Python\\Python312\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install fastparquet"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mynewenv]",
   "language": "python",
   "name": "conda-env-mynewenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
